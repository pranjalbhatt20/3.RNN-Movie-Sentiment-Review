{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 17:51:23.606596: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# test code for to show embedding\n",
    "# importing libraries\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## some sample sentence\n",
    "\n",
    "sent=['the glass of milk',\n",
    "      'the glass of juice',\n",
    "      'the cup of tea',\n",
    "      'I am a good boy',\n",
    "      'I am a good developer',\n",
    "      'understand the meaning of words',\n",
    "      'your videos are good']\n",
    "sent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining vocab size \n",
    "voc_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 3, 3, 1],\n",
       " [9, 3, 3, 6],\n",
       " [9, 1, 3, 5],\n",
       " [8, 2, 4, 9, 4],\n",
       " [8, 2, 4, 9, 1],\n",
       " [4, 9, 8, 3, 7],\n",
       " [4, 2, 3, 9]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot representation of every word\n",
    "one_hot_repr=[one_hot(words,voc_size) for words in sent] # every word willl be convert to a number of a vocab which has a size of 10000\n",
    "one_hot_repr\n",
    "# observe that the numbers are same in defferent sentence if words are same i.e. glass word in 1st and 2nd sentence have number 73531\n",
    "# when we represent first and second word in feature vector these 2 vectors will be close to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word embedding representation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0, 57127, 73531, 90600, 55928],\n",
       "       [    0,     0,     0,     0, 57127, 73531, 90600, 56487],\n",
       "       [    0,     0,     0,     0, 57127, 97759, 90600, 25055],\n",
       "       [    0,     0,     0, 78561, 17181, 38593,  6350, 68578],\n",
       "       [    0,     0,     0, 78561, 17181, 38593,  6350, 29045],\n",
       "       [    0,     0,     0, 40098, 57127, 22085, 90600, 11470],\n",
       "       [    0,     0,     0,     0, 34114, 21175, 27236,  6350]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some of the sentences are of different size , but we need to have same size in order to sent it to model \n",
    "# For this we will use pad sequence \n",
    "pad_seq_len=8\n",
    "embedding_docs=pad_sequences(one_hot_repr,padding='pre',maxlen=pad_seq_len)\n",
    "embedding_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature representation \n",
    "dim=10 # no of features for a word , max we have 300 dimension for a word \n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,dim,input_length=pad_seq_len))\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 8, 10)             1000000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,000,000\n",
      "Trainable params: 1,000,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0, 57127, 73531, 90600, 55928],\n",
       "       [    0,     0,     0,     0, 57127, 73531, 90600, 56487],\n",
       "       [    0,     0,     0,     0, 57127, 97759, 90600, 25055],\n",
       "       [    0,     0,     0, 78561, 17181, 38593,  6350, 68578],\n",
       "       [    0,     0,     0, 78561, 17181, 38593,  6350, 29045],\n",
       "       [    0,     0,     0, 40098, 57127, 22085, 90600, 11470],\n",
       "       [    0,     0,     0,     0, 34114, 21175, 27236,  6350]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedding_docs) # observe that here we dont have to fit the model as are just embedding , we can diretly use predict method to embed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
